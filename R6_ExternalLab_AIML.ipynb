{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R6_ExternalLab_AIML (2).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YYk8NG3yOIT9"},"source":["### A MNIST-like fashion product database\n","\n","In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tFO6PuxzOIT_"},"source":["### Load tensorflow"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"efNjNImfOIUC","outputId":"733d9db0-35cd-44dd-ab29-f1ea8fda48b3","executionInfo":{"status":"ok","timestamp":1575523061253,"user_tz":-330,"elapsed":3104,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":64}},"source":["import tensorflow as tf\n","tf.set_random_seed(42)"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"l9C4aAIGOIUH","outputId":"563915a8-2c28-46a9-ba74-19fe65796416","executionInfo":{"status":"ok","timestamp":1575523061256,"user_tz":-330,"elapsed":3094,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["tf.__version__"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.15.0'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HcoZBStrOIUQ"},"source":["### Collect Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XA1WsFSeOIUS","outputId":"a00725f5-f81d-40d5-e9a7-024e61555812","executionInfo":{"status":"ok","timestamp":1575523061258,"user_tz":-330,"elapsed":3086,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import keras"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qnbx7TyQOIUY","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"529b5cd2-b66e-460f-d73a-9815f908a935","executionInfo":{"status":"ok","timestamp":1575523065745,"user_tz":-330,"elapsed":7568,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}}},"source":["(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 3us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 2s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UbiHj5YPOIUc","outputId":"ed32429c-add5-48e6-9548-40669c4437e4","executionInfo":{"status":"ok","timestamp":1575523065746,"user_tz":-330,"elapsed":7559,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(testY[0:5])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[9 2 1 1 6]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lDAYzkwyOIUj"},"source":["### Convert both training and testing labels into one-hot vectors.\n","\n","**Hint:** check **tf.keras.utils.to_categorical()**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vBlfYlANOIUk","colab":{}},"source":["trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n","testY = tf.keras.utils.to_categorical(testY, num_classes=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RHV3b9mzOIUq","outputId":"5f16f505-a4c1-43bc-f9f7-bd1770988bde","scrolled":true,"executionInfo":{"status":"ok","timestamp":1575523065749,"user_tz":-330,"elapsed":7549,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["print(trainY.shape)\n","print('First 5 examples now are: ', trainY[0:5])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["(60000, 10)\n","First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FwhQ8e7VOIUw"},"source":["### Visualize the data\n","\n","Plot first 10 images in the triaining set and their labels."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AvDML2OoOIUx","outputId":"2f4d26c1-504c-4f92-e702-b60065d8b6c2","executionInfo":{"status":"ok","timestamp":1575523065755,"user_tz":-330,"elapsed":7533,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":251}},"source":["import numpy as np\n","\n","# visualizing the first 10 images in the dataset and their labels\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10, 1))\n","for i in range(10):\n","    plt.subplot(1, 10, i+1)\n","    plt.imshow(trainX[i].reshape(28, 28), cmap=\"gray\")\n","    plt.axis('off')\n","    print('label for each of the below image: %s' % (np.argmax(trainY[0:10][i])))\n","plt.show()\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["label for each of the below image: 9\n","label for each of the below image: 0\n","label for each of the below image: 0\n","label for each of the below image: 3\n","label for each of the below image: 0\n","label for each of the below image: 2\n","label for each of the below image: 7\n","label for each of the below image: 2\n","label for each of the below image: 5\n","label for each of the below image: 5\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjwAAAA9CAYAAACpzLMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmG0FDwFsAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 720x72 with 10 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"l4TbJGeSOIU4"},"source":["### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ac06XZZTOIU6","outputId":"d75c0976-2602-4157-9b29-f75d49f65b4a","executionInfo":{"status":"ok","timestamp":1575523065756,"user_tz":-330,"elapsed":7520,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["# Initialize Sequential model\n","model = tf.keras.models.Sequential()\n","\n","# Reshape data from 2D to 1D -> 28x28 to 784\n","model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n","\n","# Add Dense Layer which provides 10 Outputs after applying softmax\n","model.add(tf.keras.layers.Dense(10, activation='softmax'))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3hQpLv3aOIU_"},"source":["### Execute the model using model.fit()"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O59C_-IgOIVB","colab":{}},"source":["model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D1dNvpQrK55B","colab_type":"code","outputId":"e7463e2f-bb23-4bff-d65f-713c4dca3ea4","executionInfo":{"status":"ok","timestamp":1575523188863,"user_tz":-330,"elapsed":130597,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n","          batch_size = 32)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 3s 51us/sample - loss: 1993.5416 - acc: 0.7411 - val_loss: 1461.2876 - val_acc: 0.7959\n","Epoch 2/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1601.4836 - acc: 0.7778 - val_loss: 1058.9883 - val_acc: 0.8113\n","Epoch 3/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1545.2502 - acc: 0.7850 - val_loss: 1120.6826 - val_acc: 0.8180\n","Epoch 4/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1552.6609 - acc: 0.7882 - val_loss: 1117.0750 - val_acc: 0.8151\n","Epoch 5/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1500.0346 - acc: 0.7928 - val_loss: 1325.6685 - val_acc: 0.8000\n","Epoch 6/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1478.7821 - acc: 0.7965 - val_loss: 941.2178 - val_acc: 0.8281\n","Epoch 7/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1484.6314 - acc: 0.7949 - val_loss: 2939.8069 - val_acc: 0.7412\n","Epoch 8/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1452.7818 - acc: 0.7970 - val_loss: 1719.0944 - val_acc: 0.7284\n","Epoch 9/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1437.0149 - acc: 0.7993 - val_loss: 1375.9681 - val_acc: 0.8070\n","Epoch 10/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1448.3260 - acc: 0.8009 - val_loss: 2112.8446 - val_acc: 0.7656\n","Epoch 11/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1440.5474 - acc: 0.8000 - val_loss: 1880.6063 - val_acc: 0.7546\n","Epoch 12/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1432.1053 - acc: 0.8014 - val_loss: 993.2796 - val_acc: 0.8252\n","Epoch 13/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1390.6441 - acc: 0.8039 - val_loss: 1964.5845 - val_acc: 0.7210\n","Epoch 14/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1397.1939 - acc: 0.8029 - val_loss: 970.1565 - val_acc: 0.8249\n","Epoch 15/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1471.0691 - acc: 0.8007 - val_loss: 1393.5754 - val_acc: 0.8014\n","Epoch 16/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1389.4870 - acc: 0.8053 - val_loss: 969.4102 - val_acc: 0.8311\n","Epoch 17/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1457.2500 - acc: 0.8014 - val_loss: 1131.2567 - val_acc: 0.8176\n","Epoch 18/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1409.9338 - acc: 0.8052 - val_loss: 1355.6700 - val_acc: 0.8002\n","Epoch 19/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1376.8398 - acc: 0.8062 - val_loss: 1321.2496 - val_acc: 0.7793\n","Epoch 20/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1406.5132 - acc: 0.8033 - val_loss: 1207.9345 - val_acc: 0.7938\n","Epoch 21/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1414.9053 - acc: 0.8050 - val_loss: 1920.8478 - val_acc: 0.7375\n","Epoch 22/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1375.1357 - acc: 0.8065 - val_loss: 1558.9383 - val_acc: 0.7698\n","Epoch 23/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1379.3651 - acc: 0.8076 - val_loss: 1978.4002 - val_acc: 0.7626\n","Epoch 24/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1419.8513 - acc: 0.8041 - val_loss: 1271.9627 - val_acc: 0.7709\n","Epoch 25/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1399.8854 - acc: 0.8060 - val_loss: 1538.2015 - val_acc: 0.7868\n","Epoch 26/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1372.4833 - acc: 0.8069 - val_loss: 1944.1023 - val_acc: 0.7554\n","Epoch 27/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1394.4807 - acc: 0.8073 - val_loss: 3165.5132 - val_acc: 0.6873\n","Epoch 28/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1382.4331 - acc: 0.8052 - val_loss: 2266.7174 - val_acc: 0.7518\n","Epoch 29/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1341.5755 - acc: 0.8090 - val_loss: 1731.0645 - val_acc: 0.7847\n","Epoch 30/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1337.2664 - acc: 0.8095 - val_loss: 1180.4590 - val_acc: 0.8171\n","Epoch 31/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1374.7235 - acc: 0.8085 - val_loss: 1335.8632 - val_acc: 0.8044\n","Epoch 32/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1361.7441 - acc: 0.8079 - val_loss: 1048.0366 - val_acc: 0.8253\n","Epoch 33/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1390.2848 - acc: 0.8069 - val_loss: 2770.2616 - val_acc: 0.7715\n","Epoch 34/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1340.0992 - acc: 0.8103 - val_loss: 1621.5320 - val_acc: 0.7614\n","Epoch 35/50\n","60000/60000 [==============================] - 2s 42us/sample - loss: 1367.4560 - acc: 0.8085 - val_loss: 1042.2073 - val_acc: 0.8323\n","Epoch 36/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1396.3761 - acc: 0.8078 - val_loss: 1140.4176 - val_acc: 0.8164\n","Epoch 37/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1364.5392 - acc: 0.8089 - val_loss: 1552.8132 - val_acc: 0.7757\n","Epoch 38/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1352.1384 - acc: 0.8097 - val_loss: 2892.9574 - val_acc: 0.7613\n","Epoch 39/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1363.6683 - acc: 0.8096 - val_loss: 973.9052 - val_acc: 0.8297\n","Epoch 40/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1376.1535 - acc: 0.8095 - val_loss: 1594.5897 - val_acc: 0.8037\n","Epoch 41/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1360.5738 - acc: 0.8099 - val_loss: 1093.8967 - val_acc: 0.8271\n","Epoch 42/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1338.7982 - acc: 0.8101 - val_loss: 1144.6235 - val_acc: 0.8203\n","Epoch 43/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1391.7059 - acc: 0.8091 - val_loss: 1598.7475 - val_acc: 0.7741\n","Epoch 44/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1328.9155 - acc: 0.8116 - val_loss: 2149.6942 - val_acc: 0.7506\n","Epoch 45/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1382.8172 - acc: 0.8103 - val_loss: 1452.8595 - val_acc: 0.7920\n","Epoch 46/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1374.9800 - acc: 0.8083 - val_loss: 1397.6611 - val_acc: 0.7948\n","Epoch 47/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1341.3994 - acc: 0.8117 - val_loss: 1569.7753 - val_acc: 0.7881\n","Epoch 48/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1374.6214 - acc: 0.8097 - val_loss: 2036.4104 - val_acc: 0.7784\n","Epoch 49/50\n","60000/60000 [==============================] - 2s 40us/sample - loss: 1318.6332 - acc: 0.8124 - val_loss: 1080.5765 - val_acc: 0.8167\n","Epoch 50/50\n","60000/60000 [==============================] - 2s 41us/sample - loss: 1336.2441 - acc: 0.8119 - val_loss: 1284.6813 - val_acc: 0.8032\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f072dac9b00>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JdzDtGwDOIVF"},"source":["### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kndfpdidOIVI","colab":{}},"source":["\n","\n","# Normalize the data\n","model.add(tf.keras.layers.BatchNormalization())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6y8qEyBNK4pT","colab_type":"code","colab":{}},"source":["# Add Dense Layer which provides 10 Outputs after applying softmax\n","model.add(tf.keras.layers.Dense(10, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mwk3T5LJOIVN"},"source":["### Execute the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JNLR8tcBOIVP","colab":{}},"source":["model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8-oMrFJTmR2","colab_type":"code","outputId":"ac578f8e-ed33-4bdf-80fd-8042743a4cb2","executionInfo":{"status":"ok","timestamp":1575523339769,"user_tz":-330,"elapsed":281463,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n","          batch_size = 32)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 3s 52us/sample - loss: 1.0158 - acc: 0.7454 - val_loss: 0.7697 - val_acc: 0.8002\n","Epoch 2/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6380 - acc: 0.8340 - val_loss: 0.7291 - val_acc: 0.8027\n","Epoch 3/50\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.6092 - acc: 0.8370 - val_loss: 0.7080 - val_acc: 0.8081\n","Epoch 4/50\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.5921 - acc: 0.8483 - val_loss: 0.7047 - val_acc: 0.8194\n","Epoch 5/50\n","60000/60000 [==============================] - 3s 54us/sample - loss: 0.5974 - acc: 0.8488 - val_loss: 0.6840 - val_acc: 0.8207\n","Epoch 6/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5863 - acc: 0.8517 - val_loss: 0.7048 - val_acc: 0.8257\n","Epoch 7/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5890 - acc: 0.8557 - val_loss: 0.6826 - val_acc: 0.8229\n","Epoch 8/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6516 - acc: 0.8264 - val_loss: 0.6889 - val_acc: 0.8109\n","Epoch 9/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6043 - acc: 0.8425 - val_loss: 0.7112 - val_acc: 0.8109\n","Epoch 10/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5976 - acc: 0.8475 - val_loss: 0.6748 - val_acc: 0.8253\n","Epoch 11/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.5925 - acc: 0.8483 - val_loss: 0.6834 - val_acc: 0.8156\n","Epoch 12/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6372 - acc: 0.8378 - val_loss: 0.7222 - val_acc: 0.8088\n","Epoch 13/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6121 - acc: 0.8454 - val_loss: 0.6944 - val_acc: 0.8187\n","Epoch 14/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5822 - acc: 0.8540 - val_loss: 0.6782 - val_acc: 0.8241\n","Epoch 15/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5697 - acc: 0.8581 - val_loss: 0.6655 - val_acc: 0.8296\n","Epoch 16/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6092 - acc: 0.8391 - val_loss: 0.6891 - val_acc: 0.8082\n","Epoch 17/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6014 - acc: 0.8402 - val_loss: 0.6742 - val_acc: 0.8176\n","Epoch 18/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5827 - acc: 0.8449 - val_loss: 0.6660 - val_acc: 0.8240\n","Epoch 19/50\n","60000/60000 [==============================] - 3s 56us/sample - loss: 0.5750 - acc: 0.8509 - val_loss: 0.6712 - val_acc: 0.8259\n","Epoch 20/50\n","60000/60000 [==============================] - 3s 55us/sample - loss: 0.5845 - acc: 0.8482 - val_loss: 0.6728 - val_acc: 0.8168\n","Epoch 21/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5882 - acc: 0.8436 - val_loss: 0.6785 - val_acc: 0.8200\n","Epoch 22/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5858 - acc: 0.8467 - val_loss: 0.6901 - val_acc: 0.8125\n","Epoch 23/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.5935 - acc: 0.8353 - val_loss: 0.6722 - val_acc: 0.8124\n","Epoch 24/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5764 - acc: 0.8440 - val_loss: 0.6758 - val_acc: 0.8156\n","Epoch 25/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.5869 - acc: 0.8426 - val_loss: 0.6702 - val_acc: 0.8231\n","Epoch 26/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.5931 - acc: 0.8435 - val_loss: 0.6805 - val_acc: 0.8152\n","Epoch 27/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6791 - acc: 0.8167 - val_loss: 0.7193 - val_acc: 0.7981\n","Epoch 28/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6831 - acc: 0.8098 - val_loss: 0.7166 - val_acc: 0.7998\n","Epoch 29/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6357 - acc: 0.8286 - val_loss: 0.7060 - val_acc: 0.7924\n","Epoch 30/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6068 - acc: 0.8270 - val_loss: 0.7906 - val_acc: 0.7582\n","Epoch 31/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6854 - acc: 0.7819 - val_loss: 0.7836 - val_acc: 0.7496\n","Epoch 32/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.7176 - acc: 0.7697 - val_loss: 0.8098 - val_acc: 0.7377\n","Epoch 33/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6916 - acc: 0.7872 - val_loss: 0.7167 - val_acc: 0.7862\n","Epoch 34/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6380 - acc: 0.8190 - val_loss: 0.6935 - val_acc: 0.8073\n","Epoch 35/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.6234 - acc: 0.8255 - val_loss: 0.7308 - val_acc: 0.7920\n","Epoch 36/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6702 - acc: 0.8043 - val_loss: 0.7393 - val_acc: 0.7763\n","Epoch 37/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6759 - acc: 0.8016 - val_loss: 0.7275 - val_acc: 0.7816\n","Epoch 38/50\n","60000/60000 [==============================] - 3s 51us/sample - loss: 0.6710 - acc: 0.7983 - val_loss: 0.7432 - val_acc: 0.7708\n","Epoch 39/50\n","60000/60000 [==============================] - 3s 51us/sample - loss: 0.6781 - acc: 0.7928 - val_loss: 0.7665 - val_acc: 0.7658\n","Epoch 40/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6624 - acc: 0.7992 - val_loss: 0.7094 - val_acc: 0.7986\n","Epoch 41/50\n","60000/60000 [==============================] - 3s 51us/sample - loss: 0.5938 - acc: 0.8341 - val_loss: 0.6842 - val_acc: 0.8131\n","Epoch 42/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.5664 - acc: 0.8535 - val_loss: 0.6544 - val_acc: 0.8287\n","Epoch 43/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5572 - acc: 0.8594 - val_loss: 0.6647 - val_acc: 0.8248\n","Epoch 44/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5746 - acc: 0.8470 - val_loss: 0.6793 - val_acc: 0.8162\n","Epoch 45/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5756 - acc: 0.8468 - val_loss: 0.6716 - val_acc: 0.8207\n","Epoch 46/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.5690 - acc: 0.8499 - val_loss: 0.6706 - val_acc: 0.8198\n","Epoch 47/50\n","60000/60000 [==============================] - 3s 49us/sample - loss: 0.5933 - acc: 0.8437 - val_loss: 0.6964 - val_acc: 0.8081\n","Epoch 48/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6326 - acc: 0.8288 - val_loss: 0.7046 - val_acc: 0.8046\n","Epoch 49/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6108 - acc: 0.8360 - val_loss: 0.6948 - val_acc: 0.8095\n","Epoch 50/50\n","60000/60000 [==============================] - 3s 50us/sample - loss: 0.6108 - acc: 0.8286 - val_loss: 0.7008 - val_acc: 0.8043\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f072d564d68>"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Py-KwkmjOIVU"},"source":["### Customize the learning rate to 0.001 in sgd optimizer and run the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yLXUE9jWOIVV","colab":{}},"source":["# Create optimizer with non-default learning rate\n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n","\n","# Compile the model\n","model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pJUqA5T4OIVc","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"j9CSqKvpOIVk"},"source":["### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GGAad54JOIVm","colab":{}},"source":["#Add 1st hidden layer\n","model.add(tf.keras.layers.Dense(100, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MQ7oIymROIVp","colab":{}},"source":["#Add 2nd hidden layer\n","model.add(tf.keras.layers.Dense(100, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"X-O-fFxnOIVt","colab":{}},"source":["#Add 3rd hidden layer\n","model.add(tf.keras.layers.Dense(10, activation='sigmoid'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BiP7IL52OIVw","colab":{}},"source":["# Create optimizer with non-default learning rate\n","sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n","\n","# Compile the model\n","model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Nr2YsZV0OIV0"},"source":["## Review model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h4ojW6-oOIV2","colab":{"base_uri":"https://localhost:8080/","height":399},"outputId":"f0893c65-14fc-49ae-ecef-c07e4adc8b2d","executionInfo":{"status":"ok","timestamp":1575524809318,"user_tz":-330,"elapsed":2652,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}}},"source":["model.summary()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","reshape (Reshape)            (None, 784)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                7850      \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 10)                40        \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                110       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 100)               1100      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 100)               10100     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 10)                1010      \n","=================================================================\n","Total params: 20,210\n","Trainable params: 20,190\n","Non-trainable params: 20\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gfFGmbZLOIV5"},"source":["### Run the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bIkbMEN5OIV7","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f40f8780-862b-42ea-9266-bce045031e9b","executionInfo":{"status":"ok","timestamp":1575525236677,"user_tz":-330,"elapsed":194972,"user":{"displayName":"seema patil","photoUrl":"","userId":"00686880317668955702"}}},"source":["model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n","          batch_size = 32)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/50\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.9507 - acc: 0.6027 - val_loss: 1.0070 - val_acc: 0.5828\n","Epoch 2/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.9811 - acc: 0.5901 - val_loss: 1.0165 - val_acc: 0.5853\n","Epoch 3/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.9601 - acc: 0.6076 - val_loss: 1.0003 - val_acc: 0.6072\n","Epoch 4/50\n","60000/60000 [==============================] - 4s 62us/sample - loss: 0.9610 - acc: 0.6316 - val_loss: 1.1152 - val_acc: 0.5753\n","Epoch 5/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.0923 - acc: 0.5820 - val_loss: 1.0562 - val_acc: 0.5970\n","Epoch 6/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.9755 - acc: 0.6443 - val_loss: 0.9979 - val_acc: 0.6629\n","Epoch 7/50\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.9323 - acc: 0.6805 - val_loss: 0.9589 - val_acc: 0.6444\n","Epoch 8/50\n","60000/60000 [==============================] - 4s 71us/sample - loss: 1.1124 - acc: 0.5721 - val_loss: 0.9541 - val_acc: 0.6619\n","Epoch 9/50\n","60000/60000 [==============================] - 4s 67us/sample - loss: 0.8898 - acc: 0.6748 - val_loss: 0.9683 - val_acc: 0.6194\n","Epoch 10/50\n","60000/60000 [==============================] - 4s 67us/sample - loss: 0.8902 - acc: 0.6582 - val_loss: 0.9341 - val_acc: 0.6549\n","Epoch 11/50\n","60000/60000 [==============================] - 4s 69us/sample - loss: 0.8817 - acc: 0.6625 - val_loss: 0.9381 - val_acc: 0.6445\n","Epoch 12/50\n","60000/60000 [==============================] - 4s 67us/sample - loss: 0.8420 - acc: 0.6868 - val_loss: 0.8991 - val_acc: 0.6721\n","Epoch 13/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.9085 - acc: 0.6360 - val_loss: 1.0609 - val_acc: 0.5378\n","Epoch 14/50\n","60000/60000 [==============================] - 4s 62us/sample - loss: 1.0407 - acc: 0.5608 - val_loss: 1.0714 - val_acc: 0.5634\n","Epoch 15/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.0121 - acc: 0.5929 - val_loss: 1.0332 - val_acc: 0.6145\n","Epoch 16/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 0.9409 - acc: 0.6461 - val_loss: 1.0536 - val_acc: 0.5975\n","Epoch 17/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.0826 - acc: 0.5469 - val_loss: 1.1325 - val_acc: 0.5224\n","Epoch 18/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 1.1035 - acc: 0.5335 - val_loss: 1.2229 - val_acc: 0.4922\n","Epoch 19/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 1.1670 - acc: 0.5072 - val_loss: 1.1622 - val_acc: 0.5196\n","Epoch 20/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.1966 - acc: 0.5047 - val_loss: 1.1786 - val_acc: 0.5196\n","Epoch 21/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 1.2326 - acc: 0.5055 - val_loss: 1.2494 - val_acc: 0.4873\n","Epoch 22/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.1168 - acc: 0.5544 - val_loss: 1.1239 - val_acc: 0.5578\n","Epoch 23/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.0764 - acc: 0.5742 - val_loss: 1.1340 - val_acc: 0.5654\n","Epoch 24/50\n","60000/60000 [==============================] - 4s 66us/sample - loss: 1.0757 - acc: 0.5769 - val_loss: 1.1113 - val_acc: 0.5606\n","Epoch 25/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.0720 - acc: 0.5798 - val_loss: 1.1021 - val_acc: 0.5690\n","Epoch 26/50\n","60000/60000 [==============================] - 4s 66us/sample - loss: 1.1016 - acc: 0.5702 - val_loss: 1.4905 - val_acc: 0.4015\n","Epoch 27/50\n","60000/60000 [==============================] - 4s 62us/sample - loss: 1.2992 - acc: 0.4725 - val_loss: 1.2647 - val_acc: 0.4928\n","Epoch 28/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 1.2217 - acc: 0.5062 - val_loss: 1.2538 - val_acc: 0.4941\n","Epoch 29/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 1.1620 - acc: 0.5291 - val_loss: 1.1465 - val_acc: 0.5283\n","Epoch 30/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.0959 - acc: 0.5561 - val_loss: 1.2509 - val_acc: 0.4571\n","Epoch 31/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.2015 - acc: 0.4694 - val_loss: 1.2357 - val_acc: 0.4551\n","Epoch 32/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.2022 - acc: 0.4684 - val_loss: 1.2387 - val_acc: 0.4563\n","Epoch 33/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.1977 - acc: 0.4676 - val_loss: 1.2272 - val_acc: 0.4632\n","Epoch 34/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.1737 - acc: 0.4802 - val_loss: 1.1999 - val_acc: 0.4705\n","Epoch 35/50\n","60000/60000 [==============================] - 4s 62us/sample - loss: 1.4524 - acc: 0.3521 - val_loss: 1.4800 - val_acc: 0.3506\n","Epoch 36/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.3465 - acc: 0.4225 - val_loss: 1.2876 - val_acc: 0.4597\n","Epoch 37/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.2557 - acc: 0.4702 - val_loss: 1.2850 - val_acc: 0.4607\n","Epoch 38/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 1.1185 - acc: 0.5715 - val_loss: 1.1011 - val_acc: 0.5937\n","Epoch 39/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.0275 - acc: 0.6146 - val_loss: 1.0653 - val_acc: 0.6023\n","Epoch 40/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.0108 - acc: 0.6209 - val_loss: 1.0377 - val_acc: 0.6200\n","Epoch 41/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 0.9546 - acc: 0.6643 - val_loss: 0.9702 - val_acc: 0.6648\n","Epoch 42/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 0.9060 - acc: 0.6758 - val_loss: 0.9822 - val_acc: 0.6198\n","Epoch 43/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.1079 - acc: 0.5762 - val_loss: 1.8984 - val_acc: 0.2795\n","Epoch 44/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.4936 - acc: 0.3989 - val_loss: 1.3330 - val_acc: 0.4446\n","Epoch 45/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 1.2498 - acc: 0.4745 - val_loss: 1.2674 - val_acc: 0.4678\n","Epoch 46/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.3252 - acc: 0.4332 - val_loss: 1.3966 - val_acc: 0.3995\n","Epoch 47/50\n","60000/60000 [==============================] - 4s 65us/sample - loss: 1.4186 - acc: 0.3884 - val_loss: 1.4166 - val_acc: 0.3824\n","Epoch 48/50\n","60000/60000 [==============================] - 4s 64us/sample - loss: 1.4136 - acc: 0.3907 - val_loss: 1.4536 - val_acc: 0.3783\n","Epoch 49/50\n","60000/60000 [==============================] - 4s 63us/sample - loss: 1.4498 - acc: 0.3811 - val_loss: 1.4536 - val_acc: 0.3788\n","Epoch 50/50\n","60000/60000 [==============================] - 4s 62us/sample - loss: 1.4485 - acc: 0.3804 - val_loss: 1.4570 - val_acc: 0.3778\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f0726c00c88>"]},"metadata":{"tags":[]},"execution_count":23}]}]}